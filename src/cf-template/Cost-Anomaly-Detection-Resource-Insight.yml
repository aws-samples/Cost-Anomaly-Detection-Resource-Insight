AWSTemplateFormatVersion: '2010-09-09'
Description: AWS CADRI - Enhance the event from AWS Cost Anomaly Detection with information from the top resource IDs that contributed to the anomaly.

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: "General Configuration"
        Parameters:
          - AthenaDB
          - AthenaTable
          - QueryOutputLocation
          - CURS3Bucket
          - OrganizationId
      - Label:
          default: "Notification Flow Configuration"
        Parameters:
          - DefaultNoticationFlow
          - SenderEmail
          - RecipientEmails
    ParameterLabels:
      AthenaDB:
        default: "Athena Database"
      AthenaTable:
        default: "Athena Table"
      QueryOutputLocation:
        default: "Query Output Location"
      CURS3Bucket:
        default: "CUR S3 Bucket"
      DefaultNoticationFlow:
        default: "Default Notification Flow"
        description: "Enable the default notification flow that uses SNS to send the enhanced Cost Anomaly Detection messages?"
      SenderEmail:
        default: "Sender Email"
        description: "Verified SES email address that will send the notifications"
      RecipientEmails:
        default: "Recipient Emails"
        description: "Comma-separated list of email addresses to receive notifications"
      OrganizationId:
        default: "Organization ID for the SNS Topic Policy to get Cost Anomaly Detection alerts. See your Organization ID here: https://console.aws.amazon.com/organizations/v2/home/accounts"

Parameters:
  DefaultNoticationFlow:
    Type: String
    Default: 'yes'
    AllowedValues: ['yes', 'no']
    Description: 'Would you like to deploy the default notification flow that uses SNS to send the enhanced Cost Anomaly Detection messages?'
  SenderEmail:
    Type: String
    AllowedPattern: '[^@]+@[^@]+\.[^@]+'
    Description: 'Verified SES email address that will send the notifications. Note: This email address must have an Identity status as Verified in SES'
    ConstraintDescription: 'Please ensure that the provided email address is valid and verified in SES'
  RecipientEmails:
    Type: String
    Description: 'Comma-separated list of email addresses to receive notifications (e.g., user1@domain.com,user2@domain.com)'
    ConstraintDescription: 'Please provide valid email addresses separated by commas'
  AthenaDB:
    Type: String
    Description: 'Database that contains the table with the Cost and Usage report'
  AthenaTable:
    Type: String
    Description: 'Name of the table with the Cost and Usage report'
  QueryOutputLocation:
    Type: String
    Description: 'S3 location to store Athena query results. Only the name without S3://'
  CURS3Bucket:
    Type: String
    Description: 'S3 location where the Cost and Usage Report. Only the name without S3://'
  OrganizationId:
    Type: String
    AllowedPattern: ^o-[a-z0-9]{10,32}$
    Description: "The Organization ID (starts with 'o-') of the AWS Organization you wish to collect anomaly alerts from."
    ConstraintDescription: "The Organization ID is required to properly configure the SNS Topic Policy that will be used by Cost Anomaly Detection."

Conditions:
  ShouldDeployDefaultNotificationFlowResources:
    !Equals [!Ref DefaultNoticationFlow, "yes"]

Resources:
  EventBridgeBus:
    Type: AWS::Events::EventBus
    Properties:
      Name: !Sub ${AWS::StackName}-CADRI-EventBridge-bus
  
  EventsSNSTopic:
    Type: AWS::SNS::Topic
    Properties:
      KmsMasterKeyId: alias/aws/sns
      DisplayName: !Sub ${AWS::StackName}-CADRI-Event-topic
      TopicName: !Sub ${AWS::StackName}-CADRI-Event-topic
  
  EventsSNSPolicy:
    Type: AWS::SNS::TopicPolicy
    Properties:
      Topics:
        - !Ref EventsSNSTopic
      PolicyDocument:
        Version: "2008-10-17"
        Id: "AWS Cost Anomaly Detection Policy"
        Statement:
          - Sid: "AWSAnomalyDetectionSNSPublishingPermissions"
            Effect: "Allow"
            Principal:
              Service: "costalerts.amazonaws.com"
            Action: "SNS:Publish"
            Resource: !Ref EventsSNSTopic
            Condition:
              StringEquals:
                aws:PrincipalOrgID: !Ref OrganizationId

  LambdaEnhanceCostAnomalyDetectionFunction:
    Type: AWS::Lambda::Function
    # Test case for check skip via comment
    # checkov:skip=CKV_AWS_116: "Ensure that AWS Lambda function is configured for a Dead Letter Queue(DLQ)"
    # checkov:skip=CKV_AWS_173: "Check encryption settings for Lambda environment variable"
    # checkov:skip=CKV_AWS_117: "Ensure that AWS Lambda function is configured inside a VPC"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: "Permissions granted, CFN_Nag not parsing correctly?"
          - id: W89
            reason: "Not applicable for use case"
    Properties:
      Description: 'AWS CADRI - Lambda function that receives the event from AWS Cost Anomaly Detection and enhances the notification with the main resource IDs.'
      FunctionName: !Sub ${AWS::StackName}-CADRI-enhance-event
      Handler: index.lambda_handler
      Runtime: python3.13
      Role: !GetAtt 'LambdaEnhanceCostAnomalyRole.Arn'
      MemorySize: 128
      Timeout: 480
      Environment:
        Variables:
          ATHENA_DATABSE: !Ref AthenaDB
          ATHENA_OUTPUT_LOCATION: !Ref QueryOutputLocation
          ATHENA_TABLE: !Ref AthenaTable
          EVENT_BRIDGE_BUS_NAME: !Ref EventBridgeBus
          EVENT_BRIDGE_DETAIL_TYPE: 'CADRIEvent'
          EVENT_BRIDGE_SOURCE_NAME: 'custom.cadri'
          LOG_LEVEL: 'DEBUG'
      Code:
        ZipFile: |
          import os
          import json
          import logging
          from datetime import datetime, timedelta
          import boto3
          import time
          import traceback

          logger = logging.getLogger(__name__)
          logger.setLevel(getattr(logging, os.environ.get('LOG_LEVEL', 'INFO').upper(), logging.INFO))
          #logging.getLogger().setLevel(logging.DEBUG)

          def lambda_handler(event, context):
              logger.debug(f"Incoming event: {json.dumps(event)}")
              
              if not event.get('Records'):
                      logger.error("No Records found in event")
                      return {
                          'statusCode': 500,
                          'body': 'No Records found in event'
                      }
              processed_records = 0
              failed_records = 0
              for record in event['Records']:
                  try:
                      response, data = process_message_for_athena(record)
                      logger.debug(f"reponse type {type(response)}")
                      
                      # Ensure response is a dictionary
                      response_json = {
                          "anomalies": response if isinstance(response, list) else [response],
                          "anomaly_count": len(response) if isinstance(response, list) else 1
                      }

                      #response_json=json.loads(json.dumps(response))
                      logger.debug(f"response_json type {type(response_json)}")

                      table = format_data_as_table(data)
                      email_table = {
                          "email_table": table
                      }
                      response_json.update(email_table)
                      original_alert = json.loads(f'{{ "original_alert": {record["Sns"]["Message"]} }}')
                      logger.debug(f"original_alert type {type(original_alert)}")
                      response_json.update(original_alert)
                      logger.debug(f"json after merging: {json.dumps(response_json)}")
                      eb_result = post_to_eventbridge(response_json)
                      logger.debug(f"eb_result: {json.dumps(eb_result)}")
                      processed_records += 1
                  except Exception as e:
                          logger.error(f"Error processing record: {str(e)}")
                          logger.error(f"Failed record: {json.dumps(record)}")
                          logger.error(traceback.format_exc())
                          failed_records += 1

              logger.info(f"Processed {processed_records} records successfully. Failed to process {failed_records} records.")

              return {
                  'statusCode': 200,
                  'body': json.dumps({
                      'processed_records': processed_records,
                      'failed_records': failed_records
                  })
              }

          def post_to_eventbridge(event_detail):
              event_bus_source = os.environ.get('EVENT_BRIDGE_SOURCE_NAME')
              event_detail_type = os.environ.get('EVENT_BRIDGE_DETAIL_TYPE')
              event_bus_name = os.environ.get('EVENT_BRIDGE_BUS_NAME')
              if not event_bus_name:
                  raise Exception("EVENT_BRIDGE_BUS_NAME environment variables not set.")
              
              if not event_detail_type:
                  raise Exception("EVENT_BRIDGE_DETAIL_TYPE environment variables not set.") 
              if not event_bus_source:
                  raise Exception("EVENT_BRIDGE_SOURCE_NAME environment variables not set.") 
              
              eventbridge = boto3.client('events')
              try:
                  response = eventbridge.put_events(
                      Entries=[
                          {
                              'Source': event_bus_source,
                              'DetailType': event_detail_type,
                              'Detail': json.dumps(event_detail),
                              'EventBusName': event_bus_name  
                          }
                      ]
                  )
                  
                  return {
                      'statusCode': 200,
                      'body': json.dumps({
                          'message': 'Event published successfully',
                          'eventID': response['Entries'][0]['EventId']
                      })
                  }
                  
              except Exception as e:
                  logger.error(f"Error processing record: {str(e)}")
                  raise

          def process_message_for_athena(record):
              try:
                  message = json.loads(record['Sns']['Message'])
                  logger.info(f"Processed message {message}")
                  
                  # Create the filter condition
                  conditions = []
                  for cause in message['rootCauses']:
                      logger.debug(f"rootCauses - 1 {cause}")
                      condition = (f"line_item_usage_account_id = '{cause['linkedAccount']}' AND "
                              f"line_item_usage_type = '{cause['usageType']}' ")
                      conditions.append(condition)
                  logger.debug(f"conditions - 1 {conditions}")
                  # Join all conditions with ' OR '
                  account_service_and_usage_filter = ' OR '.join(conditions)

                  # Wrap the entire output in parentheses
                  account_service_and_usage_filter = f"({account_service_and_usage_filter})"

                  # Parse start and end dates from the event
                  start_date = datetime.strptime(message['anomalyStartDate'], "%Y-%m-%dT%H:%M:%SZ")
                  end_date = datetime.strptime(message['anomalyEndDate'], "%Y-%m-%dT%H:%M:%SZ")

                  logger.debug(f"start_date - {start_date} end_date {end_date}")
                  # Calculate the duration of the anomaly
                  duration = (end_date - start_date).days + 1

                  # Calculate date parameters for the query
                  query_start_date = start_date - timedelta(days=duration)
                  query_end_date = end_date + timedelta(days=1)
                  previous_period_start_date = start_date - timedelta(days=duration)
                  previous_period_end_date = end_date - timedelta(days=duration)

                  # Format the dates as strings for the SQL query
                  query_start_date_str = query_start_date.strftime('%Y-%m-%d')
                  query_end_date_str = query_end_date.strftime('%Y-%m-%d')
                  previous_period_start_date_str = previous_period_start_date.strftime('%Y-%m-%d')
                  previous_period_end_date_str = previous_period_end_date.strftime('%Y-%m-%d')
                  current_period_start_date_str = start_date.strftime('%Y-%m-%d')
                  current_period_end_date_str = end_date.strftime('%Y-%m-%d')

                  # Specify the Athena table name
                  table_name = os.environ.get('ATHENA_TABLE')
                  if not table_name:
                      raise Exception("ATHENA_TABLE environment variables not set.")
                  #table_name = 'cur'

                  athena_query = f"""
                      WITH daily_costs AS (
                          SELECT 
                              line_item_resource_id,
                              line_item_usage_account_id,
                              product_servicename,
                              DATE(line_item_usage_start_date) AS usage_date,
                              SUM(line_item_unblended_cost) AS total_cost
                          FROM 
                              "{table_name}"
                          WHERE 
                              {account_service_and_usage_filter}
                              AND line_item_usage_start_date >= DATE '{query_start_date_str}'
                              AND line_item_usage_start_date < DATE '{query_end_date_str}'
                          GROUP BY 
                              line_item_resource_id, 
                              line_item_usage_account_id,
                              product_servicename,
                              DATE(line_item_usage_start_date)
                      ),
                      cost_summary AS (
                          SELECT 
                              line_item_resource_id,
                              line_item_usage_account_id,
                              product_servicename,
                              SUM(CASE WHEN usage_date BETWEEN DATE '{current_period_start_date_str}' AND DATE '{current_period_end_date_str}' THEN total_cost ELSE 0 END) AS anomaly_period_cost,
                              SUM(CASE WHEN usage_date BETWEEN DATE '{previous_period_start_date_str}' AND DATE '{previous_period_end_date_str}' THEN total_cost ELSE 0 END) AS previous_period_cost
                          FROM 
                              daily_costs
                          GROUP BY 
                              line_item_resource_id,
                              line_item_usage_account_id,
                              product_servicename
                      ),
                      cost_growth AS (
                      SELECT 
                              line_item_usage_account_id,
                              product_servicename,
                              line_item_resource_id,
                              anomaly_period_cost,
                              previous_period_cost,
                              (anomaly_period_cost - previous_period_cost) AS cost_increase,
                              CASE 
                                  WHEN previous_period_cost = 0 THEN 100
                                  ELSE ((anomaly_period_cost - previous_period_cost) / previous_period_cost) * 100
                              END AS percentage_increase
                          FROM 
                              cost_summary
                      )
                      SELECT 
                          line_item_usage_account_id,
                          product_servicename,
                          line_item_resource_id,
                          anomaly_period_cost,
                          previous_period_cost,
                          cost_increase,
                          percentage_increase
                      FROM 
                          cost_growth
                      WHERE
                          cost_increase > 0
                      ORDER BY 
                          cost_increase DESC
                      LIMIT 5;
                  """
                  logger.debug(f"Generated Athena query {athena_query}")
                  results, data = run_athena_query(athena_query)
                  logger.debug(f"Athena results {json.dumps(results)}")    
                  return results, data
              except Exception as e:
                  logger.error(f"Error processing Athena message : {str(e)}")
                  logger.error(traceback.format_exc())
                  raise
              
          def run_athena_query(query_id):
              """Return answer to Bedrock Agent in expected format."""
              try:
                  # Extract parameters from the event
                  database = os.environ.get('ATHENA_DATABSE')
                  if not database:
                      raise Exception("ATHENA_DATABSE environment variables not set.")
                  output_s3_bucket = os.environ.get('ATHENA_OUTPUT_LOCATION')
                  if not output_s3_bucket:
                      raise Exception("ATHENA_OUTPUT_LOCATION environment variables not set.")
                  
                  output_location = f"s3://{output_s3_bucket}/"
                  logger.debug(f'{query_id=}')
                  
                  # Initialize Athena client
                  athena_client = boto3.client('athena')
                  response = athena_client.start_query_execution(
                      QueryString=query_id,
                      QueryExecutionContext={
                          'Database': database
                      },
                      ResultConfiguration={
                          'OutputLocation': output_location,
                      }
                  )
                  query_execution_id = response['QueryExecutionId']
                  
                  # Wait for the query to complete
                  while True:
                      query_status = athena_client.get_query_execution(QueryExecutionId=query_execution_id)
                      status = query_status['QueryExecution']['Status']['State']
                      
                      if status in ['SUCCEEDED', 'FAILED', 'CANCELLED']:
                          break
                      
                      time.sleep(1)
                  logger.debug(f"Status is  {status}")   
                  if status != 'SUCCEEDED':
                      error_message = query_status['QueryExecution']['Status'].get('AthenaError', 'Unknown error')
                      raise Exception(f"Athena query failed: {error_message}")

                  results = athena_client.get_query_results(QueryExecutionId=query_execution_id)
                  # Process the results as needed
                  rows = results['ResultSet']['Rows']
                  # First row contains column headers
                  headers = [col['VarCharValue'] for col in rows[0]['Data']]
                  
                  # Process data rows
                  data = []
                  for row in rows[1:]:
                      values = [field.get('VarCharValue', '') for field in row['Data']]
                      row_dict = dict(zip(headers, values))
                      data.append(row_dict)
                  logger.debug(f"data results --> {data}")
                  return data, rows
              except Exception as e:
                  logger.error(f"Error executing Athena query: {str(e)}")
                  logger.error(traceback.format_exc())
                  raise

          def format_data_as_table(data):
              try:
                  logger.debug(f"data in format_data_as_table {data}")
                  # Extract headers and rows from the data
                  headers = [item['VarCharValue'] for item in data[0]['Data']]
                  rows = [[entry['VarCharValue'] for entry in row['Data']] for row in data[1:]]

                  # Rename and order columns as required
                  column_names = ["Account id", "Service", "Resource id", "Current Cost", "Previous Cost", "% Growth"]
                  column_mapping = {
                      "Account id": "line_item_usage_account_id",
                      "Service": "product_servicename",
                      "Resource id": "line_item_resource_id",
                      "Current Cost": "anomaly_period_cost",
                      "Previous Cost": "previous_period_cost",
                      "% Growth": "percentage_increase",
                  }

                  mapped_rows = [
                      [
                          row[headers.index(column_mapping[column])]
                          if column_mapping[column] in headers
                          else ""
                          for column in column_names
                      ]
                      for row in rows
                  ]

                  # Adjust column widths based on the data
                  column_widths = [
                      max(len(str(item)) for item in col)
                      for col in zip(column_names, *mapped_rows)
                  ]

                  # Create the table separator
                  separator = "-" * (sum(column_widths) + len(column_widths) * 3 + 1)

                  # Format the header row
                  header_row = "| " + " | ".join(
                      column.ljust(width) for column, width in zip(column_names, column_widths)
                  ) + " |"

                  # Format the data rows
                  data_rows = [
                      "| " + " | ".join(
                          str(cell).ljust(width) for cell, width in zip(row, column_widths)
                      ) + " |"
                      for row in mapped_rows
                  ]

                  # Combine everything into the final table
                  table = "\n".join([separator, header_row, separator] + data_rows + [separator])
                  return table
              except Exception as e:
                  logger.error(traceback.format_exc())
                  raise
  
  LambdaEnhanceCostAnomalyRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Action:
              - 'sts:AssumeRole'
            Effect: 'Allow'
            Principal:
              Service:
                - 'lambda.amazonaws.com'
      Policies:
        - PolicyName: RolePolicy 
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                Resource: !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:*"
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/${AWS::StackName}-CADRI-enhance-event:*"  
              - Effect: Allow
                Action:
                  - s3:ListBucket
                  - s3:PutObject
                  - s3:GetObject
                  - s3:GetBucketLocation
                Resource:
                  - !Sub "arn:${AWS::Partition}:s3:::${QueryOutputLocation}"
                  - !Sub "arn:${AWS::Partition}:s3:::${QueryOutputLocation}/*"
                  - !Sub "arn:${AWS::Partition}:s3:::${CURS3Bucket}"
                  - !Sub "arn:${AWS::Partition}:s3:::${CURS3Bucket}/*"
              - Effect: Allow
                Action:
                  - glue:GetDatabase
                  - glue:GetTable
                  - glue:GetPartitions
                Resource:
                  - !Sub "arn:${AWS::Partition}:glue:${AWS::Region}:${AWS::AccountId}:catalog"
                  - !Sub "arn:${AWS::Partition}:glue:${AWS::Region}:${AWS::AccountId}:database/${AthenaDB}"
                  - !Sub "arn:${AWS::Partition}:glue:${AWS::Region}:${AWS::AccountId}:table/${AthenaDB}/${AthenaTable}"
              - Effect: Allow
                Action:
                  - athena:StartQueryExecution
                  - athena:GetQueryExecution
                  - athena:GetQueryResults
                Resource:
                  - !Sub "arn:${AWS::Partition}:athena:${AWS::Region}:${AWS::AccountId}:workgroup/*"
              - Effect: Allow
                Action:
                  - events:PutEvents
                Resource: !GetAtt 'EventBridgeBus.Arn'
  
  LambdaSNSSubscription:
    Type: AWS::SNS::Subscription
    Properties:
      TopicArn: !Ref EventsSNSTopic
      Protocol: lambda
      Endpoint: !GetAtt LambdaEnhanceCostAnomalyDetectionFunction.Arn

  LambdaPermissionForSNS:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref LambdaEnhanceCostAnomalyDetectionFunction
      Action: 'lambda:InvokeFunction'
      Principal: 'sns.amazonaws.com'
      SourceArn: !Ref EventsSNSTopic

  # Default Notification flow
  
  LambdaSendNotificationFunction:
    Type: AWS::Lambda::Function
    Condition: ShouldDeployDefaultNotificationFlowResources
    # Test case for check skip via comment
    # checkov:skip=CKV_AWS_173: "Check encryption settings for Lambda environment variable"
    # checkov:skip=CKV_AWS_117: "Ensure that AWS Lambda function is configured inside a VPC"
    # checkov:skip=CKV_AWS_116: "Ensure that AWS Lambda function is configured for a Dead Letter Queue(DLQ)"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: "Permissions granted, CFN_Nag not parsing correctly?"
          - id: W89
            reason: "Not applicable for use case"
    Properties:
      Description: 'AWS CADRI - Lambda function that sends the enhanced Cost Anomaly Detection notification.'
      FunctionName: !Sub ${AWS::StackName}-CADRI-send-notification
      Handler: index.lambda_handler
      Runtime: python3.13
      Role: !GetAtt 'LambdaSendNotificationRole.Arn'
      MemorySize: 128
      Timeout: 60
      Environment:
        Variables:
          LOG_LEVEL: 'INFO'
          RECIPIENT_EMAIL: !Ref RecipientEmails
          SENDER_EMAIL: !Ref SenderEmail
      Code:
        ZipFile: |
          import boto3
          import logging
          import os
          from botocore.config import Config

          logger = logging.getLogger(__name__)
          logger.setLevel(getattr(logging, os.environ.get('LOG_LEVEL', 'INFO').upper(), logging.INFO))

          # Configure exponential backoff
          retry_config = Config(
              retries={
                  'max_attempts': 5,
                  'mode': 'adaptive'
              }
          )

          def create_email_content(event):
              """
              Create HTML and text email content from CADRI anomaly event
              """
              try:
                  logger.debug(f"Processing event with {len(event.get('detail', {}).get('anomalies', []))} anomalies")
                  anomalies = event['detail']['anomalies']
                  anomaly_count = event['detail']['anomaly_count']
                  original_alert = event['detail']['original_alert']
                  
                  # Calculate total cost increase
                  total_cost_increase = sum(float(anomaly['cost_increase']) for anomaly in anomalies)
                  logger.debug(f"Total cost increase calculated: ${total_cost_increase}")
                  
                  # Create HTML table rows
                  html_rows = ""
                  text_rows = ""
                  
                  for anomaly in anomalies:
                      html_rows += f"""
                          <tr>
                              <td>{anomaly['line_item_usage_account_id']}</td>
                              <td>{anomaly['product_servicename']}</td>
                              <td style="word-break: break-all;">{anomaly['line_item_resource_id']}</td>
                              <td>${round(float(anomaly['anomaly_period_cost']), 2)}</td>
                              <td>${round(float(anomaly['previous_period_cost']), 2)}</td>
                              <td>${round(float(anomaly['cost_increase']), 2)}</td>
                              <td>{round(float(anomaly['percentage_increase']), 2)}%</td>
                          </tr>
                      """
                      
                      text_rows += f"""
              {anomaly['line_item_usage_account_id']}\t{anomaly['product_servicename']}\t{anomaly['line_item_resource_id']}\t${round(float(anomaly['anomaly_period_cost']), 2)}\t${round(float(anomaly['previous_period_cost']), 2)}\t${round(float(anomaly['cost_increase']), 2)}\t{round(float(anomaly['percentage_increase']), 2)}%"""
                  
                  # Get dates and link
                  anomaly_start_date = original_alert.get('anomalyStartDate', 'UNAVAILABLE')
                  anomaly_end_date = original_alert.get('anomalyEndDate', 'UNAVAILABLE')
                  anomaly_link = original_alert.get('anomalyDetailsLink', '')
                  
                  body_html = f"""
                  <html>
                  <head>
                      <style>
                          table {{
                              border: 1px solid #ddd;
                              padding: 0;
                              margin: 0;
                              font-size: 1em;
                              width: 100%;
                              border-collapse: collapse;
                          }}

                          table th,
                          table td {{
                              padding: 10px;
                              background: #fcfcfc;
                              text-align: center;
                              vertical-align: middle;
                              border: 1px solid #ddd;
                          }}

                          table tr:nth-child(even) td {{
                              background: #f2f2f2;
                          }}

                          table td {{
                              font-size: .85em;
                          }}

                          table thead tr th {{
                              font-size: 1em;
                              font-weight: 700;
                              background-color: #f79d2e;
                              color: #131212;
                          }}
                      </style>
                  </head>
                  <body>
                      <p>Hello,</p>
                      <p>You are receiving this alert because AWS Cost Anomaly Detection has identified an unusual cost increase. 
                      The anomaly has been validated and the root cause has been determined using the AWS Cost and Usage Report (CUR).</p>
                      
                      <p><strong>Anomaly Details:</strong></p>
                      <ul>
                          <li>Anomaly Start Date: {anomaly_start_date}</li>
                          <li>Anomaly End Date: {anomaly_end_date}</li>
                          <li>Total Anomalies: {anomaly_count}</li>
                          <li>Total Cost Increase: ${round(total_cost_increase, 2)}</li>
                      </ul>
                      
                      <h3>Resources that triggered this cost anomaly:</h3>
                      <table>
                          <thead>
                              <tr>
                                  <th>Account ID</th>
                                  <th>Service</th>
                                  <th>Resource ID</th>
                                  <th>Current Cost</th>
                                  <th>Previous Cost</th>
                                  <th>Cost Increase</th>
                                  <th>% Increase</th>
                              </tr>
                          </thead>
                          <tbody>
                              {html_rows}
                          </tbody>
                      </table>
                      
                      <p>Please verify if this cost increase is expected and, if necessary, make any adjustments.</p>
                      
                      <p>To view the original anomaly report, please <a href="{anomaly_link}">click here</a>.</p>
                      
                      <p>Thank you,<br>
                      Anomaly Detection Agent</p>
                  </body>
                  </html>
                  """
                  
                  body_text = f"""
                  Hello,
                  
                  You are receiving this alert because AWS Cost Anomaly Detection has identified an unusual cost increase.
                  The anomaly has been validated and the root cause has been determined using the AWS Cost and Usage Report (CUR).
                  
                  Anomaly Details:
                  - Anomaly Start Date: {anomaly_start_date}
                  - Anomaly End Date: {anomaly_end_date}
                  - Total Anomalies: {anomaly_count}
                  - Total Cost Increase: ${round(total_cost_increase, 2)}
                  
                  Resources that triggered this cost anomaly:
                  Account ID\tService\tResource ID\tCurrent Cost\tPrevious Cost\tCost Increase\t% Increase{text_rows}
                  
                  Please verify if this cost increase is expected and, if necessary, make any adjustments.
                  
                  To view the original anomaly report, please visit: {anomaly_link}
                  
                  Thank you,
                  Anomaly Detection Agent
                  """
                  
                  logger.debug("Email content created successfully")
                  return body_html, body_text
                  
              except Exception as e:
                  logger.error(f'Error creating email content: {str(e)}')
                  raise e

          def get_verified_emails(ses_client, email_list):
              """
              Check which emails are verified in SES
              """
              logger.debug(f"Checking verification status for emails: {email_list}")
              verified = []
              for email in email_list:
                  try:
                      response = ses_client.get_identity_verification_attributes(Identities=[email])
                      if response['VerificationAttributes'].get(email, {}).get('VerificationStatus') == 'Success':
                          verified.append(email)
                          logger.debug(f"Email {email} is verified")
                      else:
                          logger.debug(f"Email {email} is not verified")
                  except Exception as e:
                      logger.debug(f"Error checking verification for {email}: {str(e)}")
              logger.debug(f"Verified emails: {verified}")
              return verified

          def modify_email_content(body_html, body_text, unverified_emails, fallback_email):
              """
              Add notice about unverified emails to content
              """
              
              unverified_notice_html = f"""
              <div style="margin: 20px 0; padding: 10px; background-color: #fff3cd; border: 1px solid #ffeeba; border-radius: 4px;">
                  <p><strong>Note:</strong> This email was sent to {fallback_email} because the following email address is not verified in AWS SES:</p>
                  <ul>
                      {''.join(f'<li>{email}</li>' for email in unverified_emails)}
                  </ul>
                  <p>To receive these notifications directly, please contact your AWS administrator to verify these email addresses.</p>
              </div>
              """
              modified_html = body_html.replace('<body>', f'<body>{unverified_notice_html}')
              
              text_notice = f"Note: This email was intended for {', '.join(unverified_emails)} but was sent to {fallback_email} because the original recipient(s) are not verified in SES.\n\n"
              modified_text = body_text.replace('Hello,', f'Hello,\n\n{text_notice}')
              
              return modified_html, modified_text

          def lambda_handler(event, context):
              """
              Main Lambda handler for sending CADRI cost anomaly alerts via SES
              """
              try:
                  # Get environment variables
                  sender_email = os.environ.get('SENDER_EMAIL')
                  recipient_emails = os.environ.get('RECIPIENT_EMAIL')
                  
                  if not sender_email or not recipient_emails:
                      raise Exception("SENDER_EMAIL and RECIPIENT_EMAIL environment variables must be set")
                  
                  # Parse comma-separated emails
                  email_list = [email.strip() for email in recipient_emails.split(',')]
                  logger.debug(f"Parsed recipient emails: {email_list}")
                  
                  # Initialize SES client
                  ses = boto3.client('ses', config=retry_config)
                  logger.debug("SES client initialized")
                  
                  # Check verified emails
                  verified_emails = get_verified_emails(ses, email_list)
                  unverified_emails = [email for email in email_list if email not in verified_emails]
                  logger.info(f"Email verification results - Verified: {len(verified_emails)}, Unverified: {len(unverified_emails)}")
                  
                  body_html, body_text = create_email_content(event)
                  responses = []
                  logger.debug("Starting email sending process")
                  
                  # Send to verified recipients
                  if verified_emails:
                      response = ses.send_email(
                          Source=sender_email,
                          Destination={'ToAddresses': verified_emails},
                          Message={
                              'Subject': {'Charset': 'UTF-8', 'Data': 'AWS Cost Anomaly Detection Resource Insight Alert'},
                              'Body': {
                                  'Html': {'Charset': 'UTF-8', 'Data': body_html},
                                  'Text': {'Charset': 'UTF-8', 'Data': body_text},
                              },
                          },
                      )
                      responses.append(response['MessageId'])
                      logger.info(f"Email sent to verified recipients {verified_emails}. MessageId: {response['MessageId']}")
                  
                  # Send notification to sender if there are unverified emails
                  if unverified_emails:
                      modified_html, modified_text = modify_email_content(body_html, body_text, unverified_emails, sender_email)
                      response = ses.send_email(
                          Source=sender_email,
                          Destination={'ToAddresses': [sender_email]},
                          Message={
                              'Subject': {'Charset': 'UTF-8', 'Data': 'AWS Cost Anomaly Detection Resource Insight Alert - Unverified Recipients'},
                              'Body': {
                                  'Html': {'Charset': 'UTF-8', 'Data': modified_html},
                                  'Text': {'Charset': 'UTF-8', 'Data': modified_text},
                              },
                          },
                      )
                      responses.append(response['MessageId'])
                      logger.info(f"Notification sent to sender about unverified emails {unverified_emails}. MessageId: {response['MessageId']}")
                  
                  if not verified_emails and not unverified_emails:
                      logger.error("No recipients found in email list")
                      raise Exception("No recipients found")
                  
                  logger.info(f"Email sending completed successfully. Total emails sent: {len(responses)}")
                  
                  return {
                      'statusCode': 200,
                      'body': f'Successfully sent emails. MessageIds: {responses}'
                  }
                  
              except Exception as e:
                  logger.error(f"Lambda execution failed: {str(e)}")
                  return {
                      'statusCode': 500,
                      'body': f'Error sending email alert: {str(e)}'
                  }      
          
  LambdaSendNotificationRole:
    Type: AWS::IAM::Role
    Condition: ShouldDeployDefaultNotificationFlowResources
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Action:
              - 'sts:AssumeRole'
            Effect: 'Allow'
            Principal:
              Service:
                - 'lambda.amazonaws.com'
      Policies:
        - PolicyName: RolePolicy 
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                Resource: !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:*"
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/${AWS::StackName}-CADRI-send-notification:*"
              - Effect: Allow
                Action:
                  - ses:SendEmail
                  - ses:GetIdentityVerificationAttributes
                Resource: "*"
  
  EventBridgeRuleSendNotification:
    Type: AWS::Events::Rule
    Condition: ShouldDeployDefaultNotificationFlowResources
    Properties:
      Name: !Sub ${AWS::StackName}-CADRI-EventBridge-notification-rule
      Description: EventBridge rule for the default notification flow. This rule will invoke the lambda function that will send the notification email
      EventBusName: !Ref EventBridgeBus
      EventPattern:
        source:
          - "custom.cadri"
      Targets:
        - Arn: !GetAtt LambdaSendNotificationFunction.Arn
          Id: tragetNotificationLambdaFunction

  LambdaSendNotificationInvoke:
    Type: AWS::Lambda::Permission
    Condition: ShouldDeployDefaultNotificationFlowResources
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !GetAtt 'LambdaSendNotificationFunction.Arn'
      Principal: 'events.amazonaws.com'
      SourceArn: !GetAtt 'EventBridgeRuleSendNotification.Arn'

  # Validate or define SenderEmail on SES

  EmailIdentityVerification:
    Type: Custom::EmailIdentity
    Condition: ShouldDeployDefaultNotificationFlowResources
    Properties:
      ServiceToken: !GetAtt EmailVerificationFunction.Arn
      EmailIdentity: !Ref SenderEmail
      DeleteOnRemoval: false  # Optional, defaults to false
  
  EmailVerificationFunction:
    Type: AWS::Lambda::Function
    Condition: ShouldDeployDefaultNotificationFlowResources
    Properties:
      FunctionName: !Sub ${AWS::StackName}-COA-SESVerifyEmailFunction
      Handler: index.lambda_handler
      Runtime: python3.13
      Role: !GetAtt EmailVerificationRole.Arn
      MemorySize: 128
      Timeout: 15
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          import logging
          from botocore.exceptions import ClientError

          # Set up logging
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          logging.getLogger("boto3").setLevel(logging.WARNING)
          logging.getLogger("botocore").setLevel(logging.WARNING)

          def check_email_verification_status(ses_client, email):
              """
              Check if email is already verified in SES
              """
              try:
                  response = ses_client.get_identity_verification_attributes(
                      Identities=[email]
                  )
                  status = response['VerificationAttributes'].get(email, {}).get('VerificationStatus', 'NotVerified')
                  logger.info(f"Email {email} verification status: {status}")
                  return status.lower() == 'success'
              except Exception as e:
                  logger.error(f"Error checking email verification status: {str(e)}")
                  return False

          def verify_email_identity(ses_client, email):
              """
              Start email identity verification process
              """
              try:
                  ses_client.verify_email_identity(EmailAddress=email)
                  logger.info(f"Verification email sent to {email}")
                  return True
              except ClientError as e:
                  error_code = e.response['Error']['Code']
                  if error_code == 'AlreadyExists':
                      logger.info(f"Email {email} is already pending verification")
                      return True
                  else:
                      logger.error(f"Error verifying email identity: {str(e)}")
                      return False

          def delete_email_identity(ses_client, email):
              """
              Delete email identity from SES
              """
              try:
                  ses_client.delete_identity(Identity=email)
                  logger.info(f"Successfully deleted email identity {email}")
                  return True
              except Exception as e:
                  logger.error(f"Error deleting email identity: {str(e)}")
                  return False

          def lambda_handler(event, context):
              """
              Lambda handler for Custom Resource
              """
              logger.info(f"Received event: {event}")
              
              # Initialize response data
              response_data = {}
              physical_resource_id = None
              
              try:
                  # Get properties
                  properties = event.get('ResourceProperties', {})
                  email = properties.get('EmailIdentity')
                  delete_on_removal = properties.get('DeleteOnRemoval', 'true').lower() == 'true'
                  
                  if not email:
                      raise ValueError("EmailIdentity property is required")
                      
                  # Create SES client
                  ses = boto3.client('ses')
                  
                  # Set physical resource ID
                  physical_resource_id = f"ses-identity-{email}"
                  
                  if event['RequestType'] in ['Create', 'Update']:
                      # Check if already verified
                      is_verified = check_email_verification_status(ses, email)
                      
                      if is_verified:
                          logger.info(f"Email {email} is already verified")
                          response_data['Status'] = 'VERIFIED'
                      else:
                          # Start verification process
                          if verify_email_identity(ses, email):
                              response_data['Status'] = 'PENDING_VERIFICATION'
                              response_data['Message'] = f"Verification email sent to {email}"
                          else:
                              raise Exception(f"Failed to verify email identity {email}")
                      
                  elif event['RequestType'] == 'Delete':
                      if delete_on_removal:
                          if delete_email_identity(ses, email):
                              response_data['Status'] = 'DELETED'
                          else:
                              response_data['Status'] = 'DELETE_FAILED'
                      else:
                          logger.info(f"Skipping deletion of email identity {email} as DeleteOnRemoval is false")
                          response_data['Status'] = 'PRESERVED'
                  
                  cfnresponse.send(
                      event, 
                      context, 
                      cfnresponse.SUCCESS, 
                      response_data,
                      physical_resource_id
                  )
                  
              except Exception as e:
                  logger.error(f"Error: {str(e)}", exc_info=True)
                  cfnresponse.send(
                      event, 
                      context, 
                      cfnresponse.FAILED, 
                      {
                          "Error": str(e),
                          "Status": "FAILED"
                      },
                      physical_resource_id
                  )

  EmailVerificationRole:
    Type: AWS::IAM::Role
    Condition: ShouldDeployDefaultNotificationFlowResources
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Action:
              - 'sts:AssumeRole'
            Effect: 'Allow'
            Principal:
              Service:
                - 'lambda.amazonaws.com'
      Policies:
        - PolicyName: SESVerifyPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - ses:VerifyEmailIdentity
                  - ses:DeleteIdentity
                  - ses:GetIdentityVerificationAttributes
                Resource: '*'
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub 'arn:${AWS::Partition}:logs:*:*:*'

Outputs:
  SNSTopicArn:
    Description: ARN of the SNS topic to be used as part of the alert subscription for AWS Cost Anomaly Detection.
    Value: !Ref EventsSNSTopic